import asyncio
import hashlib
import os
import uuid

import pandas as pd
import json
from fastapi import HTTPException
from sqlalchemy import text
from sqlmodel import select

from apps.datasource.utils.utils import aes_decrypt
from apps.db.engine import get_engine_conn
from common.core.config import settings
from common.core.deps import SessionDep
from ...datasource.api.datasource import insert_pg
from ...datasource.crud.field import delete_field_by_ds_id
from ...datasource.crud.table import delete_table_by_ds_id
from ...datasource.models.datasource import CoreDatasource, DatasourceConf
import hashlib
import json
import os
import traceback
import uuid
import pandas as pd
from sqlalchemy import text
from fastapi import HTTPException
from common.utils.utils import SQLBotLogUtil
from apps.db.engine import get_engine_conn
from apps.datasource.crud.datasource import create_ds, getTables, update_table_and_fields
from apps.datasource.models.datasource import CreateDatasource, CoreTable, TableObj
from apps.datasource.utils.utils import aes_encrypt

path = settings.EXCEL_PATH


def delete_ds(session: SessionDep, id: int):
    """
    åˆ é™¤æ•°æ®æºï¼ˆå«è¡¨æ¸…ç†é€»è¾‘ï¼‰
    - å¯¹ Excel ç±»å‹ï¼šä¼šåˆ é™¤æ‰€æœ‰å®é™…åˆ›å»ºçš„è¡¨ã€‚
    - å¯¹å…¶ä»–ç±»å‹ï¼šä»…æ¸…ç†å…ƒæ•°æ®ã€‚
    """
    from common.utils.utils import SQLBotLogUtil

    try:
        # === Step 1: è·å–æ•°æ®æºè®°å½• ===
        term = session.exec(select(CoreDatasource).where(CoreDatasource.id == id)).first()
        if not term:
            raise HTTPException(status_code=404, detail=f"Datasource with ID {id} not found")

        SQLBotLogUtil.info(f"ğŸ§© å‡†å¤‡åˆ é™¤æ•°æ®æº ID={id}, åç§°={term.name}, ç±»å‹={term.type}")

        # === Step 2: åˆ é™¤ Excel ç±»å‹çš„ç‰©ç†è¡¨ ===
        if term.type == "excel":
            try:
                conf_raw = term.configuration or ""
                if not conf_raw.strip():
                    SQLBotLogUtil.warn(f"âš ï¸ æ•°æ®æº ID={id} æ— é…ç½®é¡¹ configurationï¼Œè·³è¿‡è¡¨åˆ é™¤ã€‚")
                else:
                    conf = DatasourceConf(**json.loads(aes_decrypt(conf_raw)))
                    engine = get_engine_conn()
                    with engine.begin() as conn:
                        for sheet in conf.sheets:
                            table_name = sheet.get("tableName")
                            if not table_name:
                                SQLBotLogUtil.warn(f"âš ï¸ è·³è¿‡æ— æ•ˆ Sheet é¡¹: {sheet}")
                                continue
                            SQLBotLogUtil.info(f"ğŸ—‘ï¸ åˆ é™¤ Excel è¡¨ï¼š{table_name}")
                            conn.execute(text(f'DROP TABLE IF EXISTS "{table_name}"'))
                    SQLBotLogUtil.info(f"âœ… å·²åˆ é™¤ Excel ç±»å‹æ•°æ®æºçš„å…¨éƒ¨è¡¨ã€‚")
            except Exception as e:
                SQLBotLogUtil.error(f"âŒ åˆ é™¤ Excel è¡¨å¤±è´¥: {traceback.format_exc()}")
                raise HTTPException(status_code=500, detail=f"Failed to drop Excel tables: {e}")

        # === Step 3: åˆ é™¤å…ƒæ•°æ® ===
        delete_table_by_ds_id(session, id)
        delete_field_by_ds_id(session, id)

        # === Step 4: åˆ é™¤æ•°æ®æºæœ¬èº« ===
        session.delete(term)
        session.commit()
        SQLBotLogUtil.info(f"âœ… æ•°æ®æºåˆ é™¤æˆåŠŸ ID={id}, åç§°={term.name}")

        return {"message": f"Datasource '{term.name}' (ID={id}) deleted successfully."}

    except HTTPException:
        # å·²çŸ¥é”™è¯¯ç›´æ¥æŠ›å‡º
        raise
    except Exception as e:
        session.rollback()
        SQLBotLogUtil.error(f"âŒ åˆ é™¤æ•°æ®æºå¼‚å¸¸: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"Delete datasource failed: {e}")
    finally:
        # æ¸…ç†äº‹åŠ¡çŠ¶æ€
        if session.is_active:
            session.commit()


def insert_pg(df, table_name, engine):
    """å°† DataFrame å†™å…¥ PostgreSQLï¼ˆreplace æ¨¡å¼ï¼‰"""
    try:
        df.to_sql(table_name, engine, if_exists="replace", index=False)
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Failed to insert table {table_name}: {e}")


def upload_excel_and_create_datasource_service(session, trans, user, save_path: str, original_filename: str):
    """
    ä¸Šä¼  Excel å¹¶è‡ªåŠ¨åˆ›å»ºæ•°æ®æºï¼ˆExcelç±»å‹ï¼‰
    ç”¨äº openapi å±‚çš„å¤ç”¨ã€‚
    - è‡ªåŠ¨è·³è¿‡ç©º sheet
    - è‡ªåŠ¨å¤„ç†é‡åæ–‡ä»¶
    - è‡ªåŠ¨åŠ å¯† configuration
    - å¼‚å¸¸æ—¶æ¸…ç†å­¤è¡¨
    """
    created_tables = []  # æˆåŠŸå¯¼å…¥çš„è¡¨å
    try:
        SQLBotLogUtil.info(f"ğŸ“‚ å¼€å§‹ä¸Šä¼ å¹¶åˆ›å»ºæ•°æ®æºï¼š{original_filename}")
        engine = get_engine_conn()

        # === Step 1: è§£æ Excel/CSV ===
        if original_filename.endswith(".csv"):
            df = pd.read_csv(save_path, engine="c")
            if df.empty or len(df.columns) == 0 or df.dropna(how="all").empty:
                SQLBotLogUtil.info(f"âš ï¸ è·³è¿‡ CSVï¼šæ— æœ‰æ•ˆæ•°æ®")
            else:
                table_name = f"sheet1_{hashlib.sha256(uuid.uuid4().bytes).hexdigest()[:10]}"
                insert_pg(df, table_name, engine)
                created_tables.append(table_name)
                SQLBotLogUtil.info(f"âœ… å¯¼å…¥ CSV å®Œæˆï¼š{table_name}")
        else:
            # é€ sheet è¯»å–
            sheet_names = pd.ExcelFile(save_path).sheet_names
            for sheet_name in sheet_names:
                df = pd.read_excel(save_path, sheet_name=sheet_name, engine="calamine")

                # âš ï¸ è·³è¿‡ç©º sheetï¼ˆè¡Œå…¨ç©º æˆ– æ— åˆ—ï¼‰
                if df.empty or len(df.columns) == 0 or df.dropna(how="all").empty:
                    SQLBotLogUtil.info(f"âš ï¸ è·³è¿‡ç©º Sheetï¼š{sheet_name}")
                    continue

                table_name = f"{sheet_name}_{hashlib.sha256(uuid.uuid4().bytes).hexdigest()[:10]}"
                insert_pg(df, table_name, engine)
                created_tables.append(table_name)
                SQLBotLogUtil.info(f"âœ… å¯¼å…¥ Sheet å®Œæˆï¼š{table_name}")

        if not created_tables:
            SQLBotLogUtil.error(f"âŒ Excel å†…æ— æœ‰æ•ˆæ•°æ®è¡¨ï¼Œç»ˆæ­¢åˆ›å»ºã€‚")
            raise HTTPException(status_code=400, detail="Excel has no valid data sheets")

        # === Step 2: æ„å»ºé…ç½®å¹¶åŠ å¯† ===
        conf_dict = {
            "file_path": save_path,
            "sheets": [{"tableName": tname, "tableComment": ""} for tname in created_tables]
        }
        configuration_encrypted = aes_encrypt(json.dumps(conf_dict, ensure_ascii=False))

        # === Step 3: æ£€æŸ¥å¹¶ç”Ÿæˆå”¯ä¸€åç§° ===
        # base_name = original_filename
        # existing_names = [
        #     row[0]
        #     for row in session.exec(
        #         select(CoreDatasource.name).where(CoreDatasource.oid == user.oid)
        #     ).all()
        # ]
        #
        # if base_name in existing_names:
        #     suffix = uuid.uuid4().hex[:6]
        #     ds_name = f"{base_name.split('.')[0]}_{suffix}.{base_name.split('.')[-1]}"
        #     SQLBotLogUtil.info(f"âš ï¸ æ£€æµ‹åˆ°åŒåæ•°æ®æºï¼Œè‡ªåŠ¨é‡å‘½åä¸ºï¼š{ds_name}")
        # else:
        #     ds_name = base_name
        suffix = uuid.uuid4().hex[:6]
        ds_name = f"{original_filename.split('.')[0]}_{suffix}.{original_filename.split('.')[-1]}"
        # === Step 4: åˆ›å»ºæ•°æ®æºå¯¹è±¡ ===
        tables_payload = [CoreTable(table_name=tname, table_comment="") for tname in created_tables]
        ds = CreateDatasource(
            name=ds_name,
            type="excel",
            configuration=configuration_encrypted,
            tables=tables_payload,
        )

        datasource = create_ds(session, trans, user, ds)
        session.flush()
        SQLBotLogUtil.info(f"âœ… æ•°æ®æºåˆ›å»ºæˆåŠŸ ID={datasource.id}")

        # === Step 5: æ›´æ–°è¡¨å­—æ®µä¿¡æ¯ ===
        try:
            for tname in created_tables:
                tables = getTables(session, datasource.id)
                for t in tables:
                    if t.table_name == tname:
                        update_table_and_fields(session, TableObj.from_orm(t))
            SQLBotLogUtil.info(f"ğŸ§¾ å·²ç™»è®° {len(created_tables)} ä¸ªè¡¨ç»“æ„")
        except Exception as e:
            SQLBotLogUtil.error(f"âš ï¸ æ›´æ–°è¡¨å­—æ®µå¤±è´¥: {e}")

        SQLBotLogUtil.info(f"ğŸ‰ ä¸Šä¼ å¹¶åˆ›å»ºæ•°æ®æºæµç¨‹å®Œæˆï¼š{ds_name}")
        return datasource

    except Exception as e:
        SQLBotLogUtil.error(f"âŒ ä¸Šä¼ å¹¶åˆ›å»ºæ•°æ®æºå¤±è´¥: {traceback.format_exc()}")
        # === Step 6: æ¸…ç†å­¤è¡¨ ===
        if created_tables:
            SQLBotLogUtil.info(f"ğŸ§¹ å¼€å§‹æ¸…ç†å­¤è¡¨ï¼Œå…± {len(created_tables)} ä¸ª")
            try:
                engine = get_engine_conn()
                with engine.connect() as conn:
                    for tname in created_tables:
                        conn.execute(text(f'DROP TABLE IF EXISTS "{tname}"'))
                        SQLBotLogUtil.info(f"ğŸ§¹ å·²æ¸…ç†å­¤è¡¨ï¼š{tname}")
                    conn.commit()
            except Exception as drop_err:
                SQLBotLogUtil.error(f"âš ï¸ æ¸…ç†å­¤è¡¨å¤±è´¥: {drop_err}")

        raise HTTPException(status_code=500, detail=f"Upload and create datasource failed: {e}")
